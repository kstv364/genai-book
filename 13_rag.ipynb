{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C. End-to-End Retrieval-Augmented Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a supplementary material for the Appendix C of the [Hands-On Generative AI with Transformers and Diffusion Models book](https://learning.oreilly.com/library/view/hands-on-generative-ai/9781098149239/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The-AI-Act.pdf downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Define the file name and URL\n",
    "file_name = \"The-AI-Act.pdf\"\n",
    "url = \"https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf\"\n",
    "\n",
    "# Download the file\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "print(f\"{file_name} downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_community pypdf langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_name)\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user or for own use on the Union market for its intended purpose;  \\n(12) ‘intended purpose’ means the use for which an AI system is intended by the provider, \\nincluding the specific context and conditions of use,  as specified in the information \\nsupplied by the provider in the instructions for use, promotional or sales materials \\nand statements, as well as in the technical documentation;  \\n(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way tha t is not in'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_text = [chunk.page_content for chunk in chunks]\n",
    "chunked_text[404]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding the Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# Compute embedding for both sentences\n",
    "embedding_1 = model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8367]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8367, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1 @ embedding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8367, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.dot(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = model.encode(chunked_text, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 384])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, top_k=5):\n",
    "    # Encode the query into a vector\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity between the query and all document chunks\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, chunk_embeddings)\n",
    "\n",
    "    # Get the top k most similar chunks\n",
    "    top_k_indices = similarities[0].topk(top_k).indices\n",
    "\n",
    "    # Retrieve the corresponding document chunks\n",
    "    results = [chunked_text[i] for i in top_k_indices]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TITLE  II \\nPROHIBITED  ARTIFICIAL  INTELLIGENCE  PRACTICES  \\nArticle 5  \\n1. The following artificial intelligence practices shall be prohibited:  \\n(a) the placing on the market, putting into service or use of an A I system that \\ndeploys subliminal techniques beyond a person’s consciousness in order to \\nmaterially distort a person’s behaviour in a manner that causes or is likely to \\ncause that person or another person physical or psychological harm;',\n",
       " 'low or minimal risk. The list of prohibited practices in Title II comprises all those AI systems \\nwhose use is considered unacceptable as contravening Unio n values, for instance by violating \\nfundamental rights. The prohibitions covers practices that have a significant potential to \\nmanipulate persons  through subliminal techniques beyond their consciousness or exploit']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_documents(\"What are prohibited ai practices?\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from genaibook.core import get_device\n",
    "\n",
    "device = get_device()\n",
    "generator = pipeline(\n",
    "    \"text-generation\", model=\"HuggingFaceTB/SmolLM-135M-Instruct\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    # Retrieve relevant chunks\n",
    "    context_chunks = search_documents(query, top_k=2)\n",
    "\n",
    "    # Combine the chunks into a single context string\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "\n",
    "    # Generate a response using the context\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "    # Define the context to be passed to the model\n",
    "    system_prompt = (\n",
    "        \"You are a friendly assistant that answers questions about the AI Act. \"\n",
    "        \"If the user is not making a question, you can ask for clarification\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    response = generator(messages, max_new_tokens=300)\n",
    "    return response[0][\"generated_text\"][2][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EU Act prohibits the use of artificial intelligence practices that are harmful to individuals, such as:\n",
      "\n",
      "* The placing on the market, putting into service or use of an A I system that is subliminal, that is, it is not intended to be used for any purpose other than to deceive or manipulate individuals.\n",
      "* The use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "* The use of A I systems that are designed to manipulate individuals, such as those used in surveillance or monitoring.\n",
      "\n",
      "The EU Act prohibits the use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "\n",
      "The EU Act prohibits the use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "\n",
      "The EU Act prohibits the use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "\n",
      "The EU Act prohibits the use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "\n",
      "The EU Act prohibits the use of A I systems that are designed to deceive or manipulate individuals, such as those used in advertising, marketing, or customer service.\n",
      "\n",
      "The EU Act prohibits the use of A I systems\n"
     ]
    }
   ],
   "source": [
    "answer = generate_answer(\"What are prohibited ai practices in the EU act?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
